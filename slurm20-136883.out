Sun Aug  4 10:29:56 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100 80GB PCIe          Off | 00000000:01:00.0 Off |                   On |
| N/A   30C    P0              43W / 300W |     87MiB / 81920MiB |     N/A      Default |
|                                         |                      |              Enabled |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| MIG devices:                                                                          |
+------------------+--------------------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |
|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |
|                  |                                |        ECC|                       |
|==================+================================+===========+=======================|
|  0    7   0   0  |              12MiB /  9728MiB  | 14      0 |  1   0    0    0    0 |
|                  |               0MiB / 16383MiB  |           |                       |
+------------------+--------------------------------+-----------+-----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
 10:29:57 up 103 days, 22:36,  7 users,  load average: 0.03, 0.47, 0.53
Training epoch 1 / 50
Total batch reconstruction loss: 0.29037219285964966
Epoch [1/50], Train Loss: 0.1812, Validation Loss: 0.1521
Training epoch 2 / 50
Total batch reconstruction loss: 0.2652863562107086
Epoch [2/50], Train Loss: 0.1708, Validation Loss: 0.1415
Training epoch 3 / 50
Total batch reconstruction loss: 0.2402704507112503
Epoch [3/50], Train Loss: 0.1633, Validation Loss: 0.1436
Training epoch 4 / 50
Total batch reconstruction loss: 0.21870557963848114
Epoch [4/50], Train Loss: 0.1624, Validation Loss: 0.1500
Training epoch 5 / 50
Total batch reconstruction loss: 0.19971436262130737
Epoch [5/50], Train Loss: 0.1622, Validation Loss: 0.1565
Training epoch 6 / 50
Total batch reconstruction loss: 0.18478074669837952
Epoch [6/50], Train Loss: 0.1632, Validation Loss: 0.1582
Training epoch 7 / 50
Total batch reconstruction loss: 0.173854261636734
Epoch [7/50], Train Loss: 0.1679, Validation Loss: 0.1609
Training epoch 8 / 50
Total batch reconstruction loss: 0.1620287299156189
Epoch [8/50], Train Loss: 0.1676, Validation Loss: 0.1562
Training epoch 9 / 50
Total batch reconstruction loss: 0.15142503380775452
Epoch [9/50], Train Loss: 0.1644, Validation Loss: 0.1541
Training epoch 10 / 50
Total batch reconstruction loss: 0.14201125502586365
Epoch [10/50], Train Loss: 0.1527, Validation Loss: 0.1499
Training epoch 11 / 50
Total batch reconstruction loss: 0.13716107606887817
Epoch [11/50], Train Loss: 0.1434, Validation Loss: 0.1459
Training epoch 12 / 50
Total batch reconstruction loss: 0.13091230392456055
Epoch [12/50], Train Loss: 0.1337, Validation Loss: 0.1414
Training epoch 13 / 50
Total batch reconstruction loss: 0.12352032959461212
Epoch [13/50], Train Loss: 0.1278, Validation Loss: 0.1352
Training epoch 14 / 50
Total batch reconstruction loss: 0.11580097675323486
Epoch [14/50], Train Loss: 0.1223, Validation Loss: 0.1298
Training epoch 15 / 50
Total batch reconstruction loss: 0.111378975212574
Epoch [15/50], Train Loss: 0.1202, Validation Loss: 0.1274
Training epoch 16 / 50
Total batch reconstruction loss: 0.109174445271492
Epoch [16/50], Train Loss: 0.1191, Validation Loss: 0.1218
Training epoch 17 / 50
Total batch reconstruction loss: 0.10764136910438538
Epoch [17/50], Train Loss: 0.1178, Validation Loss: 0.1204
Training epoch 18 / 50
Total batch reconstruction loss: 0.10473442077636719
Epoch [18/50], Train Loss: 0.1152, Validation Loss: 0.1188
Training epoch 19 / 50
Total batch reconstruction loss: 0.09992063790559769
Epoch [19/50], Train Loss: 0.1100, Validation Loss: 0.1184
Training epoch 20 / 50
Total batch reconstruction loss: 0.09650149941444397
Epoch [20/50], Train Loss: 0.1069, Validation Loss: 0.1184
Training epoch 21 / 50
Total batch reconstruction loss: 0.09601995348930359
Epoch [21/50], Train Loss: 0.1080, Validation Loss: 0.1198
Training epoch 22 / 50
Total batch reconstruction loss: 0.09427067637443542
Epoch [22/50], Train Loss: 0.1067, Validation Loss: 0.1188
Training epoch 23 / 50
Total batch reconstruction loss: 0.09168541431427002
Epoch [23/50], Train Loss: 0.1047, Validation Loss: 0.1167
Training epoch 24 / 50
Total batch reconstruction loss: 0.08972214162349701
Epoch [24/50], Train Loss: 0.1032, Validation Loss: 0.1163
Training epoch 25 / 50
Total batch reconstruction loss: 0.08831462264060974
Epoch [25/50], Train Loss: 0.1016, Validation Loss: 0.1159
Training epoch 26 / 50
Total batch reconstruction loss: 0.08703360706567764
Epoch [26/50], Train Loss: 0.1003, Validation Loss: 0.1167
Training epoch 27 / 50
Total batch reconstruction loss: 0.08587808161973953
Epoch [27/50], Train Loss: 0.0994, Validation Loss: 0.1182
Training epoch 28 / 50
Total batch reconstruction loss: 0.0860796868801117
Epoch [28/50], Train Loss: 0.1007, Validation Loss: 0.1174
Training epoch 29 / 50
Total batch reconstruction loss: 0.08478513360023499
Epoch [29/50], Train Loss: 0.0989, Validation Loss: 0.1169
Training epoch 30 / 50
Total batch reconstruction loss: 0.08385701477527618
Epoch [30/50], Train Loss: 0.0982, Validation Loss: 0.1165
Training epoch 31 / 50
Total batch reconstruction loss: 0.08292249590158463
Epoch [31/50], Train Loss: 0.0974, Validation Loss: 0.1156
Training epoch 32 / 50
Total batch reconstruction loss: 0.08284639567136765
Epoch [32/50], Train Loss: 0.0981, Validation Loss: 0.1165
Training epoch 33 / 50
Total batch reconstruction loss: 0.08177065849304199
Epoch [33/50], Train Loss: 0.0970, Validation Loss: 0.1173
Training epoch 34 / 50
Total batch reconstruction loss: 0.08147802948951721
Epoch [34/50], Train Loss: 0.0974, Validation Loss: 0.1167
Training epoch 35 / 50
Total batch reconstruction loss: 0.07962825894355774
Epoch [35/50], Train Loss: 0.0946, Validation Loss: 0.1173
Training epoch 36 / 50
Total batch reconstruction loss: 0.080479696393013
Epoch [36/50], Train Loss: 0.0972, Validation Loss: 0.1147
Training epoch 37 / 50
Total batch reconstruction loss: 0.07918910682201385
Epoch [37/50], Train Loss: 0.0951, Validation Loss: 0.1151
Training epoch 38 / 50
Total batch reconstruction loss: 0.07935099303722382
Epoch [38/50], Train Loss: 0.0959, Validation Loss: 0.1150
Training epoch 39 / 50
Total batch reconstruction loss: 0.07820409536361694
Epoch [39/50], Train Loss: 0.0940, Validation Loss: 0.1157
Training epoch 40 / 50
Total batch reconstruction loss: 0.07790158689022064
Epoch [40/50], Train Loss: 0.0938, Validation Loss: 0.1152
Training epoch 41 / 50
Total batch reconstruction loss: 0.07724814116954803
Epoch [41/50], Train Loss: 0.0931, Validation Loss: 0.1151
Training epoch 42 / 50
Total batch reconstruction loss: 0.07741120457649231
Epoch [42/50], Train Loss: 0.0941, Validation Loss: 0.1155
Training epoch 43 / 50
Total batch reconstruction loss: 0.07656168937683105
Epoch [43/50], Train Loss: 0.0929, Validation Loss: 0.1168
Training epoch 44 / 50
Total batch reconstruction loss: 0.07657937705516815
Epoch [44/50], Train Loss: 0.0933, Validation Loss: 0.1153
Training epoch 45 / 50
Total batch reconstruction loss: 0.0758838802576065
Epoch [45/50], Train Loss: 0.0925, Validation Loss: 0.1142
Training epoch 46 / 50
Total batch reconstruction loss: 0.07566120475530624
Epoch [46/50], Train Loss: 0.0923, Validation Loss: 0.1141
Training epoch 47 / 50
Total batch reconstruction loss: 0.07616270333528519
Epoch [47/50], Train Loss: 0.0936, Validation Loss: 0.1140
Training epoch 48 / 50
Total batch reconstruction loss: 0.07558639347553253
Epoch [48/50], Train Loss: 0.0927, Validation Loss: 0.1143
Training epoch 49 / 50
Total batch reconstruction loss: 0.07441623508930206
Epoch [49/50], Train Loss: 0.0908, Validation Loss: 0.1147
Training epoch 50 / 50
Total batch reconstruction loss: 0.07518216222524643
Epoch [50/50], Train Loss: 0.0927, Validation Loss: 0.1168
